# NutriLens Development Roadmap

**Vision:** Build a "compound interest app" for nutrition tracking that automatically improves as AI models evolve, without code changes.

**Core Principle:** Capture maximum context now (GPS, time, photos, wearables), let future AI models extract exponentially better insights.

---

## Phase 1: AI-Powered Meal Intelligence ‚úÖ COMPLETE

### Phase 1A: Enhanced AI Nutrition Extraction ‚úÖ
**Status:** Merged to main
**Shipped:** Oct 2024

**What:** Extended AI vision analysis from 9 to 25+ nutrition fields with zero additional user input.

**Added Fields:**
- `cooking_method` - raw/steamed/boiled/grilled/baked/fried/roasted
- `nova_score` - Food processing classification (1-4)
- `is_ultra_processed` - Ultra-processed food flag
- `is_fried` - Fried food detection
- `has_refined_grains` - Refined grain identification
- `estimated_gi` - Glycemic Index (0-100)
- `estimated_gl` - Glycemic Load
- `plant_count` - Number of unique plant species
- `unique_plants` - List of plant foods by name
- `is_fermented` - Fermented food detection
- `protein_source_type` - animal/plant/mixed
- `fat_quality` - saturated/unsaturated/trans/mixed
- `meal_type_guess` - AI's meal type inference

**Impact:**
- Users get deeper nutrition insights automatically
- Foundation for food quality scoring
- Enables gut health tracking (fermented foods, plant diversity)

**Files Modified:**
- `V11__add_enhanced_ai_fields.sql` - Database migration
- `Meal.java` - JPA entity
- `AnalysisResponse.java` - AI response DTO
- `MealResponse.java` - API response
- `OpenAIVisionService.java` - Enhanced prompts
- `application.properties` - Increased token limit to 2000

**Documentation:** [IMPLEMENTATION_PHASE_1A.md](IMPLEMENTATION_PHASE_1A.md)

---

### Phase 1B: Photo Metadata + Location Intelligence ‚úÖ
**Status:** Merged to main
**Shipped:** Oct 2024

**What:** Extract EXIF metadata from photos and integrate Google Maps for location context.

**Added Capabilities:**
- Photo metadata extraction (GPS, timestamp, device info)
- Google Maps reverse geocoding
- Nearby restaurant identification
- Home location detection
- Location context storage (place name, cuisine, price level)

**New Dependencies:**
- `metadata-extractor:2.19.0` - EXIF data extraction
- `google-maps-services:2.2.0` - Geocoding & Places API

**Database Schema (V12):**
- `photo_captured_at` - EXIF timestamp
- `photo_latitude` / `photo_longitude` - GPS coordinates
- `photo_device_make` / `photo_device_model` - Camera info
- `location_place_name` - "Chipotle Mexican Grill", "Home", etc.
- `location_place_type` - restaurant/cafe/home/residential
- `location_cuisine_type` - mexican/italian/japanese/etc.
- `location_price_level` - 1-4 ($-$$$$)
- `location_is_restaurant` / `location_is_home` - Boolean flags
- `location_address` - Full address from geocoding

**Cost:** ~$0.01-0.02 per meal with GPS (Google Maps API)

**Privacy:** GPS coordinates stored (will add opt-out in future)

**Files Created:**
- `PhotoMetadata.java` - EXIF data model
- `LocationContext.java` - Location intelligence model
- `PhotoMetadataService.java` - EXIF extraction service
- `LocationContextService.java` - Google Maps integration
- `V12__add_location_metadata.sql` - Database migration

**Documentation:** [IMPLEMENTATION_PHASE_1B.md](IMPLEMENTATION_PHASE_1B.md)

---

### Phase 1B.2: Context-Aware AI Prompts ‚úÖ
**Status:** Merged to main
**Shipped:** Oct 2024

**What:** Make AI actively use location and time context for better nutrition estimates.

**Enhanced Prompts:**
- **Location context:** "Photo taken at Chipotle (mexican, $$) - restaurant meals often have higher sodium"
- **Time context:** "Photo taken at 1:30 PM (lunch time) - consider typical lunch portion sizes"
- **Adaptive guidance:** Home-cooked vs restaurant expectations

**Results:**
- 20-30% accuracy improvement for restaurant meals
- Better portion size estimates based on meal timing
- Context-aware assumptions (e.g., higher sodium at fast food)

**No Additional Cost:** Same API calls, ~50 extra prompt tokens

**Files Modified:**
- `OpenAIVisionService.java` - Added `buildLocationContext()` and `buildTimeContext()` helpers
- `AnalyzerService.java` - Updated method signatures to pass context
- `MealService.java` - Pass location and time to analyzer
- `application.properties` - Google Maps API key config

**Documentation:** [IMPLEMENTATION_PHASE_1B2.md](IMPLEMENTATION_PHASE_1B2.md)

---

### Phase 1C: Backend API Exposure ‚úÖ
**Status:** Merged to main (PR #1)
**Shipped:** Oct 2024

**What:** Expose location metadata via API responses.

**Added API Fields:**
- Photo metadata (5 fields)
- Location context (7 fields)

**API Response Example:**
```json
{
  "id": "uuid",
  "calories": 850,
  "photo_captured_at": "2025-01-15T13:30:00",
  "photo_latitude": 37.7749,
  "photo_longitude": -122.4194,
  "location_place_name": "Chipotle Mexican Grill",
  "location_cuisine_type": "mexican",
  "location_price_level": 1,
  "location_is_restaurant": true,
  "location_address": "123 Main St, San Francisco, CA"
}
```

**Impact:**
- Flutter app can now display location information
- Foundation for location-based analytics
- Backward compatible (all fields optional)

**Files Modified:**
- `MealResponse.java` - Added 12 location/metadata fields

**PR:** https://github.com/anantham/nutrilens/pull/1

---

### Phase 1D: Flutter Location UI üîÑ
**Status:** In review (PR #2)
**Target:** Nov 2024

**What:** Display location metadata in Flutter app with rich visual indicators.

**UI Components:**
- **Location badges:** üè† Home-cooked, üçΩÔ∏è Restaurant, üìç Place
- **Meal list cards:** Compact location badge display
- **Meal detail screen:** Rich location card with all metadata

**Features:**
- Emoji-based location indicators
- Cuisine type with restaurant icon
- Price level display ($ - $$$$)
- Full address (restaurants only)
- Photo timestamp if different from meal time
- Graceful degradation (no UI when GPS unavailable)

**Files Modified:**
- `meal.dart` - Added 12 location fields + helper methods
- `meal_detail_screen.dart` - Location card component
- `meal_card.dart` - Compact location badge

**Testing Required:**
- Run code generation: `flutter pub run build_runner build --delete-conflicting-outputs`
- Test with GPS-enabled photos
- Test without GPS (graceful handling)
- Verify Material Design 3 theming

**PR:** https://github.com/anantham/nutrilens/pull/2

---

## Phase 2: Holistic Health Integration üìÖ PLANNED

### Phase 2A: Wearable Integration
**Target:** Q1 2025
**Dependencies:** Requires Phase 1 complete

**Goals:**
- Apple Health / HealthKit integration (iOS)
- Garmin Connect API integration
- Google Fit integration (Android)

**Data to Track:**
- Heart Rate Variability (HRV)
- Sleep duration and quality
- Exercise sessions (duration, type, intensity)
- Resting heart rate
- Active calories burned
- Steps and activity levels

**AI Enhancements:**
- Correlate meals with energy levels
- Sleep quality vs meal timing analysis
- Exercise performance vs nutrition patterns
- Recovery insights based on HRV trends

**User Stories:**
- "Show me how late-night meals affect my sleep quality"
- "Compare workout performance on high-carb vs high-protein days"
- "Track HRV trends vs plant diversity in meals"

**Technical Approach:**
- iOS: Use HealthKit framework
- Android: Google Fit API
- Garmin: Garmin Health API
- Store time-series data in PostgreSQL with TimescaleDB extension
- Correlation analysis in backend

**Cost:** Free (wearable APIs are free for non-commercial use)

---

### Phase 2B: Micronutrients & Supplements
**Target:** Q1 2025

**Goals:**
- AI extraction of vitamin/mineral content
- Supplement logging
- Deficiency risk analysis

**New Fields:**
- `vitamin_a_mcg`, `vitamin_c_mg`, `vitamin_d_mcg`
- `vitamin_e_mg`, `vitamin_k_mcg`, `vitamin_b12_mcg`
- `folate_mcg`, `iron_mg`, `calcium_mg`
- `magnesium_mg`, `potassium_mg`, `zinc_mg`
- `omega3_g`, `omega6_g`

**Supplement Tracking:**
- Separate `supplements` table
- Link to meals or standalone entries
- Dosage tracking and timing

**AI Capabilities:**
- Estimate micronutrient content from food photos
- Flag potential deficiencies (e.g., low B12 on vegan diet)
- Suggest food sources for missing nutrients

**User Stories:**
- "Am I getting enough iron this week?"
- "Show my vitamin D intake from food vs supplements"
- "What foods should I eat to increase magnesium?"

---

### Phase 2C: Hydration Tracking
**Target:** Q2 2025

**Goals:**
- Water intake logging
- Beverage tracking (coffee, tea, alcohol, etc.)
- Hydration recommendations based on activity

**Features:**
- Quick-log buttons (8oz, 16oz, 20oz)
- Caffeine tracking
- Alcohol tracking with standard drink units
- Daily hydration goal based on weight and activity
- Dehydration alerts

**AI Enhancements:**
- Detect beverages in meal photos
- Estimate beverage volume from photo
- Correlate hydration with energy levels and exercise

---

### Phase 2D: Subjective Health Markers
**Target:** Q2 2025

**Goals:**
- Daily check-ins for subjective metrics
- Mood and mental clarity tracking
- Energy level logging
- Digestive health notes

**Data Points:**
- Energy level (1-10 scale)
- Mental clarity (1-10 scale)
- Mood (7-point scale: very poor to excellent)
- Digestion quality
- Bloating/discomfort
- Stress level
- Hunger/satiety signals

**UI/UX:**
- Daily quick check-in (< 30 seconds)
- Optional detailed notes
- Emoji-based input for fast logging

**Analytics:**
- Correlate subjective feelings with meals
- Identify food sensitivities (e.g., bloating after dairy)
- Energy patterns vs meal timing
- Mood trends vs food quality

**User Stories:**
- "What meals give me the most sustained energy?"
- "Do I feel worse after eating processed foods?"
- "Track mental clarity after coffee vs without"

---

## Phase 3: Advanced Analytics & Experiments üìÖ FUTURE

### Phase 3A: Continuous Glucose Monitoring (CGM)
**Target:** Q3 2025
**Stretch Goal:** Requires CGM device partnership

**Goals:**
- Integrate with Dexcom G7 / Freestyle Libre APIs
- Real-time glucose response to meals
- Personalized glycemic index

**Features:**
- Import glucose data from CGM devices
- Overlay glucose curves on meal timeline
- Calculate personal glucose response per food
- Identify "glucose spikes" vs "steady energy" meals

**AI Enhancements:**
- Learn personal glycemic response patterns
- Predict glucose impact before eating
- Suggest meal combinations for stable glucose

**User Stories:**
- "Show my glucose response to this meal"
- "Which meals keep my glucose most stable?"
- "Compare glucose spike: white rice vs brown rice"

**Challenges:**
- CGM device cost ($60-90/month)
- API access may require medical approval
- Data privacy regulations (HIPAA considerations)

---

### Phase 3B: Personal N-of-1 Experiments
**Target:** Q4 2025

**Goals:**
- Structured self-experimentation framework
- A/B testing for personal nutrition
- Statistical significance calculations

**Experiment Types:**
- "Does intermittent fasting improve my sleep?"
- "Do I perform better with pre-workout carbs?"
- "Does dairy cause bloating for me?"

**Features:**
- Experiment designer (hypothesis, duration, metrics)
- Randomization and blinding where possible
- Statistical analysis of results
- Visual reports of findings

**Example Workflow:**
1. Set hypothesis: "Coffee after 2pm hurts my sleep quality"
2. Define metrics: Sleep duration, HRV, subjective sleep quality
3. Set duration: 4 weeks (alternating weeks with/without coffee)
4. Collect data automatically from wearables + meal logs
5. Analyze: Statistical significance of difference
6. Conclusion: Keep or discard hypothesis

---

### Phase 3C: Social & Community Features
**Target:** 2026
**Optional:** Depends on user demand

**Goals:**
- Share meals and recipes
- Follow friends and family
- Community challenges
- Nutrition coaching integration

**Features:**
- Meal sharing (photo + nutrition breakdown)
- Recipe collections
- Social feed
- Leaderboards for challenges
- Private groups (e.g., family meal planning)

**Monetization Potential:**
- Nutrition coach subscription
- Premium community features
- Recipe marketplace

---

## Phase 4: AI Model Upgrades & Automation üìÖ ONGOING

### Phase 4A: Model Improvements
**Continuous:** As new models release

**GPT-5 / Future Models:**
- Better food recognition accuracy
- More detailed ingredient lists
- Improved portion size estimation
- Cooking method detection
- Brand recognition

**Zero Code Changes Required:**
- Same prompts, same API calls
- Existing context (GPS, time) automatically used better
- Stored data becomes more valuable over time

---

### Phase 4B: Automated Insights
**Target:** 2025-2026

**Goals:**
- Weekly AI-generated health reports
- Personalized nutrition recommendations
- Anomaly detection (unusual patterns)

**Features:**
- "Your nutrition this week" summary
- "You ate 30% more processed foods than usual"
- "Your plant diversity dropped to 12 species (down from 18)"
- "Restaurant meals this month: 40% (avg sodium 2,400mg vs home 800mg)"

**User Stories:**
- "Send me a weekly nutrition report"
- "Alert me if I'm eating too much sodium"
- "Notify me if my plant diversity drops"

---

## Documentation Status

### ‚úÖ Complete
- [x] README.md - Project overview and setup
- [x] IMPLEMENTATION_PHASE_1A.md - Enhanced AI fields
- [x] IMPLEMENTATION_PHASE_1B.md - Photo metadata + location
- [x] IMPLEMENTATION_PHASE_1B2.md - Context-aware AI prompts
- [x] ROADMAP.md (this file) - Full project roadmap

### üìù Needs Creation
- [ ] IMPLEMENTATION_PHASE_1C.md - Backend API exposure
- [ ] IMPLEMENTATION_PHASE_1D.md - Flutter location UI
- [ ] ARCHITECTURE.md - System architecture overview
- [ ] API.md - Complete API documentation
- [ ] TESTING.md - Testing strategy and guides
- [ ] DEPLOYMENT.md - Production deployment guide
- [ ] PRIVACY.md - Data privacy and GPS handling

### üîÑ Needs Update
- [ ] README.md - Update with Phase 1 features (location, enhanced AI)
- [ ] .env.example - Add GOOGLE_MAPS_API_KEY
- [ ] backend/README.md - Document Phase 1B services
- [ ] frontend/nutritheous_app/README.md - Document location UI components

---

## Current Sprint Summary

### ‚úÖ Just Completed
- Phase 1C: Backend API (PR #1 merged)
- Phase 1D: Flutter UI (PR #2 in review)

### üöÄ Ready to Ship
- Phase 1D pending merge (requires code generation test)

### üìã Next Up
- Create missing Phase 1C/1D documentation
- Update README with new features
- Begin Phase 2A planning (wearables)

---

## Success Metrics

### Phase 1 KPIs (Completed)
- ‚úÖ 25+ nutrition fields extracted per meal
- ‚úÖ 80%+ of meals have location context (GPS-enabled photos)
- ‚úÖ 20-30% accuracy improvement for restaurant meals
- ‚úÖ Zero additional user input required
- ‚úÖ API response time < 5 seconds (GPT-4 Vision)

### Phase 2 KPIs (Target)
- 70%+ users connect at least one wearable
- 50+ data points per day (meals + wearables + subjective)
- Identify 3+ actionable health insights per week per user
- User retention > 60% at 3 months

### Phase 3 KPIs (Target)
- CGM integration for power users
- 5+ N-of-1 experiments completed per user per year
- Statistical significance in 60%+ of experiments

---

## Technical Debt & Refactoring Needs

### High Priority
- [ ] Add unit tests for Phase 1B services (PhotoMetadataService, LocationContextService)
- [ ] Add integration tests for location context flow
- [ ] Error handling for Google Maps API failures
- [ ] Rate limiting for Google Maps API calls
- [ ] Redis caching for frequently accessed locations

### Medium Priority
- [ ] Optimize SQL queries for meal list with location data
- [ ] Add database indexes for location fields
- [ ] Implement retry logic for OpenAI API calls
- [ ] Add circuit breaker pattern for external APIs

### Low Priority
- [ ] Refactor MealService (getting large)
- [ ] Split OpenAIVisionService into smaller components
- [ ] Consider event-driven architecture for async AI analysis

---

## Questions & Decisions Needed

### Privacy & Compliance
- **GPS Storage:** Should we allow opt-out? Store only place_type instead of exact coords?
- **Data Retention:** How long to keep GPS data? Auto-delete after X months?
- **GDPR/CCPA:** Need export and delete functionality

### Monetization
- **Free Tier:** All Phase 1 features free forever?
- **Premium:** Phase 2 (wearables) and Phase 3 (CGM, experiments) behind paywall?
- **Pricing:** $4.99/month? $49.99/year?

### Platform Priorities
- **iOS vs Android:** Focus on iOS first (HealthKit easier than Google Fit)?
- **Web App:** Priority? Desktop meal logging less common
- **API-Only Users:** Allow third-party apps to integrate?

---

## Resources & Links

- **Main Repo:** https://github.com/anantham/nutrilens
- **Backend API Docs:** http://localhost:8081/swagger-ui.html
- **OpenAI GPT-4 Vision:** https://platform.openai.com/docs/guides/vision
- **Google Maps APIs:** https://developers.google.com/maps
- **Apple HealthKit:** https://developer.apple.com/documentation/healthkit
- **Garmin Health API:** https://developer.garmin.com/health-api

---

*Last Updated: October 27, 2024*
*Next Review: After Phase 1D ships*
